{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FALCON Dataset Preprocessing\n",
    "\n",
    "This notebook preprocesses the **FALCON** (Fallacies in COVID-19 Network-based) dataset for use in our semantic web pipeline.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "FALCON is a multi-label dataset of COVID-19-related tweets annotated for six fallacy types:\n",
    "- Ad Hominem\n",
    "- Appeal to Fear\n",
    "- Appeal to Ridicule\n",
    "- False Dilemma\n",
    "- Hasty Generalization\n",
    "- Loaded Language\n",
    "\n",
    "**Source files:** `df_train.csv`, `df_val.csv`, `df_test.csv` (2,916 tweets total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/luncenok/Studia/sem7/SWSN/semantic_web_project\n",
      "FALCON data: /Users/luncenok/Studia/sem7/SWSN/semantic_web_project/data/input/unprocessed/falcon_dataset\n",
      "Output dir: /Users/luncenok/Studia/sem7/SWSN/semantic_web_project/data/input/processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"input\"\n",
    "FALCON_DIR = DATA_DIR / \"unprocessed\" / \"falcon_dataset\"\n",
    "OUTPUT_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"FALCON data: {FALCON_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load FALCON Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1811 rows\n",
      "Val: 550 rows\n",
      "Test: 555 rows\n",
      "Total: 2916 rows\n"
     ]
    }
   ],
   "source": [
    "# Load all splits\n",
    "train_df = pd.read_csv(FALCON_DIR / \"df_train.csv\")\n",
    "val_df = pd.read_csv(FALCON_DIR / \"df_val.csv\")\n",
    "test_df = pd.read_csv(FALCON_DIR / \"df_test.csv\")\n",
    "\n",
    "# Add split indicator\n",
    "train_df['split'] = 'train'\n",
    "val_df['split'] = 'val'\n",
    "test_df['split'] = 'test'\n",
    "\n",
    "# Combine\n",
    "falcon_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} rows\")\n",
    "print(f\"Val: {len(val_df)} rows\")\n",
    "print(f\"Test: {len(test_df)} rows\")\n",
    "print(f\"Total: {len(falcon_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 133\n",
      "\n",
      "Key columns: ['new_id', 'component_id', 'main_tweet', 'previous_context', 'posterior_context', 'Ad Hominem', 'Appeal to Fear', 'Appeal to Ridicule', 'False Dilemma', 'Hasty Generalization', 'Loaded Language', 'None of the above', 'created_at', 'followers', 'tweet_count']\n"
     ]
    }
   ],
   "source": [
    "# Check columns\n",
    "print(f\"Total columns: {len(falcon_df.columns)}\")\n",
    "print(f\"\\nKey columns: {falcon_df.columns[:15].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Fallacy Columns and Ontology Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology Mapping:\n",
      "  Ad Hominem                -> AdHominem\n",
      "  Appeal to Fear            -> FearAppeal\n",
      "  Appeal to Ridicule        -> AppealToRidicule\n",
      "  False Dilemma             -> FalseDilemma\n",
      "  Hasty Generalization      -> HastyGeneralization\n",
      "  Loaded Language           -> LoadedLanguage\n"
     ]
    }
   ],
   "source": [
    "# Fallacy columns in FALCON\n",
    "FALLACY_COLUMNS = [\n",
    "    'Ad Hominem',\n",
    "    'Appeal to Fear',\n",
    "    'Appeal to Ridicule',\n",
    "    'False Dilemma',\n",
    "    'Hasty Generalization',\n",
    "    'Loaded Language'\n",
    "]\n",
    "\n",
    "# Mapping to our ontology classes\n",
    "FALLACY_TO_ONTOLOGY = {\n",
    "    'Ad Hominem': 'AdHominem',\n",
    "    'Appeal to Fear': 'FearAppeal',\n",
    "    'Appeal to Ridicule': 'AppealToRidicule',\n",
    "    'False Dilemma': 'FalseDilemma',\n",
    "    'Hasty Generalization': 'HastyGeneralization',\n",
    "    'Loaded Language': 'LoadedLanguage'\n",
    "}\n",
    "\n",
    "print(\"Ontology Mapping:\")\n",
    "for falcon_name, onto_name in FALLACY_TO_ONTOLOGY.items():\n",
    "    print(f\"  {falcon_name:25} -> {onto_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Fallacy Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallacy Distribution:\n",
      "==================================================\n",
      "Ad Hominem                  259 (  8.9%)\n",
      "Appeal to Fear              157 (  5.4%)\n",
      "Appeal to Ridicule          238 (  8.2%)\n",
      "False Dilemma               168 (  5.8%)\n",
      "Hasty Generalization         91 (  3.1%)\n",
      "Loaded Language             457 ( 15.7%)\n",
      "\n",
      "Tweets with â‰¥1 fallacy: 1009 (34.6%)\n"
     ]
    }
   ],
   "source": [
    "# Fallacy counts\n",
    "print(\"Fallacy Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "for col in FALLACY_COLUMNS:\n",
    "    count = falcon_df[col].sum()\n",
    "    pct = count / len(falcon_df) * 100\n",
    "    print(f\"{col:25} {count:5} ({pct:5.1f}%)\")\n",
    "\n",
    "# Tweets with at least one fallacy\n",
    "falcon_df['fallacy_count'] = falcon_df[FALLACY_COLUMNS].sum(axis=1)\n",
    "with_fallacy = (falcon_df['fallacy_count'] > 0).sum()\n",
    "print(f\"\\nTweets with â‰¥1 fallacy: {with_fallacy} ({with_fallacy/len(falcon_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fallacies per tweet:\n",
      "fallacy_count\n",
      "0    1907\n",
      "1     708\n",
      "2     250\n",
      "3      42\n",
      "4       9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of fallacy count per tweet\n",
    "print(\"\\nFallacies per tweet:\")\n",
    "print(falcon_df['fallacy_count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: OMG!!! @realDonaldTrump is DESTROYING America!!! ðŸ‡ºðŸ‡¸ #MAGA https://t.co/xyz123\n",
      "Cleaned:  OMG! realDonaldTrump is DESTROYING America! ðŸ‡ºðŸ‡¸ MAGA [URL]\n",
      "\n",
      "FALCON original: [user79987]: @user @user ... @user The unintelligent thing\n",
      "FALCON cleaned:  [user79987]: . The unintelligent thing\n"
     ]
    }
   ],
   "source": [
    "def clean_tweet_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean tweet text for NLP processing.\n",
    "    \n",
    "    Normalizations:\n",
    "    - Remove anonymized @user mentions (no entity info)\n",
    "    - Keep real @mentions (remove @ symbol only)\n",
    "    - Replace URLs with [URL]\n",
    "    - Remove hashtag symbols (keep text)\n",
    "    - Normalize whitespace\n",
    "    - Collapse repeated punctuation\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Replace URLs\n",
    "    text = re.sub(r'https?://\\S+', '[URL]', text)\n",
    "    \n",
    "    # Remove anonymized @user mentions entirely (no entity info)\n",
    "    text = re.sub(r'@user\\b', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # For real mentions, remove @ symbol but keep username (for NER)\n",
    "    text = re.sub(r'@(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Remove hashtag symbols but keep text\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Collapse repeated punctuation\n",
    "    text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Test\n",
    "test_text = \"OMG!!! @realDonaldTrump is DESTROYING America!!! ðŸ‡ºðŸ‡¸ #MAGA https://t.co/xyz123\"\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Cleaned:  {clean_tweet_text(test_text)}\")\n",
    "\n",
    "# Test with anonymized mentions\n",
    "test_falcon = \"[user79987]: @user @user ... @user The unintelligent thing\"\n",
    "print(f\"\\nFALCON original: {test_falcon}\")\n",
    "print(f\"FALCON cleaned:  {clean_tweet_text(test_falcon)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset: 2916 rows\n",
      "Columns: ['post_id', 'text', 'text_clean', 'techniques', 'has_persuasion', 'split', 'source']\n"
     ]
    }
   ],
   "source": [
    "def process_falcon(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process FALCON dataset for pipeline use.\n",
    "    \n",
    "    Returns DataFrame with:\n",
    "    - post_id: unique identifier\n",
    "    - text: original tweet text\n",
    "    - text_clean: normalized text\n",
    "    - techniques: list of ontology class names\n",
    "    - has_persuasion: binary flag\n",
    "    - split: train/val/test\n",
    "    \"\"\"\n",
    "    processed = pd.DataFrame()\n",
    "    \n",
    "    # Generate unique IDs\n",
    "    processed['post_id'] = [f\"falcon_{i}\" for i in range(len(df))]\n",
    "    \n",
    "    # Text columns\n",
    "    processed['text'] = df['main_tweet'].values\n",
    "    processed['text_clean'] = df['main_tweet'].apply(clean_tweet_text)\n",
    "    \n",
    "    # Extract techniques as list of ontology classes\n",
    "    def get_techniques(row):\n",
    "        techniques = []\n",
    "        for col in FALLACY_COLUMNS:\n",
    "            if row[col] == 1:\n",
    "                techniques.append(FALLACY_TO_ONTOLOGY[col])\n",
    "        return techniques\n",
    "    \n",
    "    processed['techniques'] = df.apply(get_techniques, axis=1)\n",
    "    processed['has_persuasion'] = (df[FALLACY_COLUMNS].sum(axis=1) > 0).astype(int)\n",
    "    \n",
    "    # Keep split info\n",
    "    processed['split'] = df['split'].values\n",
    "    \n",
    "    # Source dataset marker\n",
    "    processed['source'] = 'FALCON'\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# Process\n",
    "processed_df = process_falcon(falcon_df)\n",
    "\n",
    "print(f\"Processed dataset: {len(processed_df)} rows\")\n",
    "print(f\"Columns: {processed_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[user104337]: @user @user ... @user Kyrie Irv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[user79987]: @user @user ... @user Totally di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[user104337]: @user @user ... @user That's so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[user79987]: @user @user ... @user The uninte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[user47446]: @user @user ... @user It's been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[user1779]: @user @user ... @user this shit's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[user47446]: @user @user ... @user Companies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[user47446]: @user @user ... @user Plus how d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[user1779]: @user @user ... @user exactly. bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[user47446]: @user @user ... @user Why must w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          main_tweet\n",
       "0   [user104337]: @user @user ... @user Kyrie Irv...\n",
       "1   [user79987]: @user @user ... @user Totally di...\n",
       "2   [user104337]: @user @user ... @user That's so...\n",
       "3   [user79987]: @user @user ... @user The uninte...\n",
       "4   [user47446]: @user @user ... @user It's been ...\n",
       "5   [user1779]: @user @user ... @user this shit's...\n",
       "6   [user47446]: @user @user ... @user Companies ...\n",
       "7   [user47446]: @user @user ... @user Plus how d...\n",
       "8   [user1779]: @user @user ... @user exactly. bo...\n",
       "9   [user47446]: @user @user ... @user Why must w..."
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_df[['main_tweet']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>techniques</th>\n",
       "      <th>has_persuasion</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>falcon_0</td>\n",
       "      <td>[user104337]: . Kyrie Irving just doesn't get ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>falcon_1</td>\n",
       "      <td>[user79987]: . Totally disagree here. You hit ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>falcon_2</td>\n",
       "      <td>[user104337]: . That's so unintelligent. You c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>falcon_3</td>\n",
       "      <td>[user79987]: . The unintelligent thing to do w...</td>\n",
       "      <td>[AdHominem, LoadedLanguage]</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>falcon_4</td>\n",
       "      <td>[user47446]: . It's been what.2, 3 weeks and w...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>falcon_5</td>\n",
       "      <td>[user1779]: . this shit's not gonna be easyðŸ˜‚no...</td>\n",
       "      <td>[LoadedLanguage]</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>falcon_6</td>\n",
       "      <td>[user47446]: . Companies across the world are ...</td>\n",
       "      <td>[HastyGeneralization]</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>falcon_7</td>\n",
       "      <td>[user47446]: . Plus how do you know they'll do...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>falcon_8</td>\n",
       "      <td>[user1779]: . exactly. boycotting will stop a ...</td>\n",
       "      <td>[FalseDilemma]</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>falcon_9</td>\n",
       "      <td>[user47446]: . Why must we always be combative...</td>\n",
       "      <td>[FalseDilemma]</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id                                         text_clean  \\\n",
       "0  falcon_0  [user104337]: . Kyrie Irving just doesn't get ...   \n",
       "1  falcon_1  [user79987]: . Totally disagree here. You hit ...   \n",
       "2  falcon_2  [user104337]: . That's so unintelligent. You c...   \n",
       "3  falcon_3  [user79987]: . The unintelligent thing to do w...   \n",
       "4  falcon_4  [user47446]: . It's been what.2, 3 weeks and w...   \n",
       "5  falcon_5  [user1779]: . this shit's not gonna be easyðŸ˜‚no...   \n",
       "6  falcon_6  [user47446]: . Companies across the world are ...   \n",
       "7  falcon_7  [user47446]: . Plus how do you know they'll do...   \n",
       "8  falcon_8  [user1779]: . exactly. boycotting will stop a ...   \n",
       "9  falcon_9  [user47446]: . Why must we always be combative...   \n",
       "\n",
       "                    techniques  has_persuasion  split  \n",
       "0                           []               0  train  \n",
       "1                           []               0  train  \n",
       "2                           []               0  train  \n",
       "3  [AdHominem, LoadedLanguage]               1  train  \n",
       "4                           []               0  train  \n",
       "5             [LoadedLanguage]               1  train  \n",
       "6        [HastyGeneralization]               1  train  \n",
       "7                           []               0  train  \n",
       "8               [FalseDilemma]               1  train  \n",
       "9               [FalseDilemma]               1  train  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview processed data\n",
    "processed_df[['post_id', 'text_clean', 'techniques', 'has_persuasion', 'split']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FALCON PREPROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total tweets: 2916\n",
      "  - Train: 1811\n",
      "  - Val: 550\n",
      "  - Test: 555\n",
      "\n",
      "With persuasion techniques: 1009 (34.6%)\n",
      "\n",
      "Avg text length: 182.0 chars\n",
      "\n",
      "Technique counts:\n",
      "  LoadedLanguage              457\n",
      "  AdHominem                   259\n",
      "  AppealToRidicule            238\n",
      "  FalseDilemma                168\n",
      "  FearAppeal                  157\n",
      "  HastyGeneralization          91\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FALCON PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal tweets: {len(processed_df)}\")\n",
    "print(f\"  - Train: {(processed_df['split'] == 'train').sum()}\")\n",
    "print(f\"  - Val: {(processed_df['split'] == 'val').sum()}\")\n",
    "print(f\"  - Test: {(processed_df['split'] == 'test').sum()}\")\n",
    "\n",
    "print(f\"\\nWith persuasion techniques: {processed_df['has_persuasion'].sum()} ({processed_df['has_persuasion'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nAvg text length: {processed_df['text_clean'].str.len().mean():.1f} chars\")\n",
    "\n",
    "print(\"\\nTechnique counts:\")\n",
    "all_techniques = [t for techniques in processed_df['techniques'] for t in techniques]\n",
    "from collections import Counter\n",
    "for technique, count in Counter(all_techniques).most_common():\n",
    "    print(f\"  {technique:25} {count:5}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSV: /Users/luncenok/Studia/sem7/SWSN/semantic_web_project/data/input/processed/falcon_processed.csv\n",
      "Exported JSON: /Users/luncenok/Studia/sem7/SWSN/semantic_web_project/data/input/processed/falcon_processed.json\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export as CSV\n",
    "csv_path = OUTPUT_DIR / \"falcon_processed.csv\"\n",
    "processed_df.to_csv(csv_path, index=False)\n",
    "print(f\"Exported CSV: {csv_path}\")\n",
    "\n",
    "# Export as JSON (better for list fields)\n",
    "json_path = OUTPUT_DIR / \"falcon_processed.json\"\n",
    "processed_df.to_json(json_path, orient='records', indent=2)\n",
    "print(f\"Exported JSON: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON contains 2916 records\n",
      "\n",
      "Sample record:\n",
      "{\n",
      "  \"post_id\": \"falcon_3\",\n",
      "  \"text\": \" [user79987]: @user @user ... @user The unintelligent thing to do would be to go on living like nothing happened. If you have leverage use it. See how quickly a rich ass owner who doesn't care will hold on to something that doesn't generate profits. Contracts don't mean a damn thing anymore...haven't in years. \\n \",\n",
      "  \"text_clean\": \"[user79987]: . The unintelligent thing to do would be to go on living like nothing happened. If you have leverage use it. See how quickly a rich ass owner who doesn't care will hold on to something that doesn't generate profits. Contracts don't mean a damn thing anymore.haven't in years.\",\n",
      "  \"techniques\": [\n",
      "    \"AdHominem\",\n",
      "    \"LoadedLanguage\"\n",
      "  ],\n",
      "  \"has_persuasion\": 1,\n",
      "  \"split\": \"train\",\n",
      "  \"source\": \"FALCON\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Verify JSON export\n",
    "with open(json_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"JSON contains {len(data)} records\")\n",
    "print(f\"\\nSample record:\")\n",
    "print(json.dumps(data[3], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "The processed FALCON dataset is now ready for:\n",
    "\n",
    "1. **NLP Analysis** - Entity extraction with spaCy\n",
    "2. **LLM Processing** - Claim extraction and technique detection with Gemini\n",
    "3. **RDF Generation** - Creating semantic triples for knowledge graph\n",
    "\n",
    "Output files:\n",
    "- `data/input/processed/falcon_processed.csv` - CSV format\n",
    "- `data/input/processed/falcon_processed.json` - JSON format (preserves list fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
