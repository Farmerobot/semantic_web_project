{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimental Results: Persuasion-Aware MUSE Pipeline\n",
        "\n",
        "This notebook presents **experimental results** from running our semantic web pipeline on the FALCON dataset.\n",
        "\n",
        "## Contents\n",
        "1. Pipeline Execution on FALCON Data\n",
        "2. Results Analysis\n",
        "3. Comparison with Baseline (MUSE Framework)\n",
        "4. SPARQL Query Examples\n",
        "5. Insights and Conclusions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Pipeline Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: c:\\Users\\msi\\Documents\\semantic_web\n",
            "Project root: c:\\Users\\msi\\Documents\\semantic_web\n",
            "Output directory: c:\\Users\\msi\\Documents\\semantic_web\\data\\output\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# Change to project root so relative paths in pipeline work correctly\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "os.chdir(PROJECT_ROOT)\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"output\"\n",
        "INPUT_DIR = PROJECT_ROOT / \"data\" / \"input\" / \"processed\"\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Run the Pipeline\n",
        "\n",
        "Execute the main pipeline on FALCON data. This processes posts through:\n",
        "- Claim extraction (LLM)\n",
        "- Persuasion technique detection (LLM)\n",
        "- Entity recognition & Wikidata linking (spaCy + SPARQL)\n",
        "- RDF triple generation (RDFLib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-15 16:19:37,624 - INFO - Starting Persuasion-Aware MUSE Pipeline\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input file: data/input/processed/falcon_processed.json\n",
            "Max posts to process: 15\n",
            "Confidence threshold: 0.6\n",
            "\n",
            "============================================================\n",
            "RUNNING PIPELINE...\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-15 16:19:38,157 - INFO - OpenRouter client initialized with model: google/gemini-2.5-flash-lite\n",
            "2025-12-15 16:19:38,647 - INFO - spaCy model loaded successfully\n",
            "2025-12-15 16:19:38,661 - INFO - Loaded 15 posts from FALCON dataset\n",
            "2025-12-15 16:19:38,664 - INFO - Processing batch 1\n",
            "2025-12-15 16:19:38,664 - INFO - Processing post: falcon_0\n",
            "2025-12-15 16:19:38,666 - INFO - Extracting claims from post: falcon_0\n",
            "2025-12-15 16:19:39,897 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:40,631 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:19:40,634 - INFO - Detecting persuasion in claim: falcon_0_1\n",
            "2025-12-15 16:19:41,002 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:41,699 - INFO - Detecting persuasion in claim: falcon_0_2\n",
            "2025-12-15 16:19:42,101 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:43,005 - INFO - Detecting persuasion in claim: falcon_0_3\n",
            "2025-12-15 16:19:43,370 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:44,303 - INFO -   Detected 7 persuasion techniques\n",
            "2025-12-15 16:19:44,305 - INFO - Extracting entities from claim: falcon_0_1\n",
            "2025-12-15 16:19:44,324 - INFO - Extracting entities from claim: falcon_0_2\n",
            "2025-12-15 16:19:44,343 - INFO - Extracting entities from claim: falcon_0_3\n",
            "2025-12-15 16:19:44,614 - INFO -   Linked 1 entities\n",
            "2025-12-15 16:19:44,618 - INFO - Verifying claim: falcon_0_1\n",
            "2025-12-15 16:19:44,619 - INFO - Verifying claim: falcon_0_2\n",
            "2025-12-15 16:19:44,624 - INFO - Verifying claim: falcon_0_3\n",
            "2025-12-15 16:19:44,627 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:19:44,631 - INFO - Generating RDF triples for post: falcon_0\n",
            "2025-12-15 16:19:44,644 - INFO -   Generated 37 RDF triples\n",
            "2025-12-15 16:19:44,652 - INFO - Processing post: falcon_1\n",
            "2025-12-15 16:19:44,654 - INFO - Extracting claims from post: falcon_1\n",
            "2025-12-15 16:19:45,118 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:45,530 - INFO -   Extracted 2 claims\n",
            "2025-12-15 16:19:45,535 - INFO - Detecting persuasion in claim: falcon_1_1\n",
            "2025-12-15 16:19:46,556 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:47,580 - INFO - Detecting persuasion in claim: falcon_1_2\n",
            "2025-12-15 16:19:48,089 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:48,807 - INFO -   Detected 5 persuasion techniques\n",
            "2025-12-15 16:19:48,812 - INFO - Extracting entities from claim: falcon_1_1\n",
            "2025-12-15 16:19:49,318 - INFO - Extracting entities from claim: falcon_1_2\n",
            "2025-12-15 16:19:49,597 - INFO -   Linked 2 entities\n",
            "2025-12-15 16:19:49,599 - INFO - Verifying claim: falcon_1_1\n",
            "2025-12-15 16:19:49,603 - INFO - Verifying claim: falcon_1_2\n",
            "2025-12-15 16:19:49,606 - INFO -   Verified 2 claims\n",
            "2025-12-15 16:19:49,613 - INFO - Generating RDF triples for post: falcon_1\n",
            "2025-12-15 16:19:49,624 - INFO -   Generated 33 RDF triples\n",
            "2025-12-15 16:19:49,627 - INFO - Processing post: falcon_2\n",
            "2025-12-15 16:19:49,630 - INFO - Extracting claims from post: falcon_2\n",
            "2025-12-15 16:19:49,981 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:50,550 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:19:50,553 - INFO - Detecting persuasion in claim: falcon_2_1\n",
            "2025-12-15 16:19:50,892 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:51,747 - INFO - Detecting persuasion in claim: falcon_2_2\n",
            "2025-12-15 16:19:52,098 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:53,115 - INFO - Detecting persuasion in claim: falcon_2_3\n",
            "2025-12-15 16:19:53,475 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:19:54,538 - INFO -   Detected 8 persuasion techniques\n",
            "2025-12-15 16:19:54,539 - INFO - Extracting entities from claim: falcon_2_1\n",
            "2025-12-15 16:19:54,728 - INFO - Extracting entities from claim: falcon_2_2\n",
            "2025-12-15 16:20:00,252 - INFO - Extracting entities from claim: falcon_2_3\n",
            "2025-12-15 16:20:00,347 - INFO -   Linked 4 entities\n",
            "2025-12-15 16:20:00,347 - INFO - Verifying claim: falcon_2_1\n",
            "2025-12-15 16:20:00,349 - INFO - Verifying claim: falcon_2_2\n",
            "2025-12-15 16:20:00,353 - INFO - Verifying claim: falcon_2_3\n",
            "2025-12-15 16:20:00,354 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:00,354 - INFO - Generating RDF triples for post: falcon_2\n",
            "2025-12-15 16:20:00,357 - INFO -   Generated 49 RDF triples\n",
            "2025-12-15 16:20:00,358 - INFO - Processing post: falcon_3\n",
            "2025-12-15 16:20:00,360 - INFO - Extracting claims from post: falcon_3\n",
            "2025-12-15 16:20:00,886 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:01,307 - INFO -   Extracted 2 claims\n",
            "2025-12-15 16:20:01,307 - INFO - Detecting persuasion in claim: falcon_3_1\n",
            "2025-12-15 16:20:01,309 - INFO - Detecting persuasion in claim: falcon_3_2\n",
            "2025-12-15 16:20:01,309 - INFO -   Detected 4 persuasion techniques\n",
            "2025-12-15 16:20:01,309 - INFO - Extracting entities from claim: falcon_3_1\n",
            "2025-12-15 16:20:01,328 - INFO - Extracting entities from claim: falcon_3_2\n",
            "2025-12-15 16:20:01,555 - INFO -   Linked 1 entities\n",
            "2025-12-15 16:20:01,558 - INFO - Verifying claim: falcon_3_1\n",
            "2025-12-15 16:20:01,560 - INFO - Verifying claim: falcon_3_2\n",
            "2025-12-15 16:20:01,562 - INFO -   Verified 2 claims\n",
            "2025-12-15 16:20:01,562 - INFO - Generating RDF triples for post: falcon_3\n",
            "2025-12-15 16:20:01,566 - INFO -   Generated 25 RDF triples\n",
            "2025-12-15 16:20:01,568 - INFO - Processing post: falcon_4\n",
            "2025-12-15 16:20:01,570 - INFO - Extracting claims from post: falcon_4\n",
            "2025-12-15 16:20:01,914 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:02,543 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:20:02,545 - INFO - Detecting persuasion in claim: falcon_4_1\n",
            "2025-12-15 16:20:02,940 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:04,336 - INFO - Detecting persuasion in claim: falcon_4_2\n",
            "2025-12-15 16:20:04,729 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:05,656 - INFO - Detecting persuasion in claim: falcon_4_3\n",
            "2025-12-15 16:20:05,997 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:06,667 - INFO -   Detected 6 persuasion techniques\n",
            "2025-12-15 16:20:06,668 - INFO - Extracting entities from claim: falcon_4_1\n",
            "2025-12-15 16:20:06,924 - INFO - Extracting entities from claim: falcon_4_2\n",
            "2025-12-15 16:20:06,968 - INFO - Extracting entities from claim: falcon_4_3\n",
            "2025-12-15 16:20:12,255 - INFO -   Linked 2 entities\n",
            "2025-12-15 16:20:12,261 - INFO - Verifying claim: falcon_4_1\n",
            "2025-12-15 16:20:12,268 - INFO - Verifying claim: falcon_4_2\n",
            "2025-12-15 16:20:12,271 - INFO - Verifying claim: falcon_4_3\n",
            "2025-12-15 16:20:12,274 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:12,278 - INFO - Generating RDF triples for post: falcon_4\n",
            "2025-12-15 16:20:12,290 - INFO -   Generated 40 RDF triples\n",
            "2025-12-15 16:20:12,295 - INFO - Processing batch 2\n",
            "2025-12-15 16:20:12,300 - INFO - Processing post: falcon_5\n",
            "2025-12-15 16:20:12,303 - INFO - Extracting claims from post: falcon_5\n",
            "2025-12-15 16:20:12,975 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:13,689 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:20:13,695 - INFO - Detecting persuasion in claim: falcon_5_1\n",
            "2025-12-15 16:20:13,697 - INFO - Detecting persuasion in claim: falcon_5_2\n",
            "2025-12-15 16:20:13,700 - INFO - Detecting persuasion in claim: falcon_5_3\n",
            "2025-12-15 16:20:13,700 - INFO -   Detected 3 persuasion techniques\n",
            "2025-12-15 16:20:13,709 - INFO - Extracting entities from claim: falcon_5_1\n",
            "2025-12-15 16:20:13,963 - INFO - Extracting entities from claim: falcon_5_2\n",
            "2025-12-15 16:20:13,999 - INFO - Extracting entities from claim: falcon_5_3\n",
            "2025-12-15 16:20:14,307 - INFO -   Linked 2 entities\n",
            "2025-12-15 16:20:14,313 - INFO - Verifying claim: falcon_5_1\n",
            "2025-12-15 16:20:14,315 - INFO - Verifying claim: falcon_5_2\n",
            "2025-12-15 16:20:14,319 - INFO - Verifying claim: falcon_5_3\n",
            "2025-12-15 16:20:14,324 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:14,334 - INFO - Generating RDF triples for post: falcon_5\n",
            "2025-12-15 16:20:14,347 - INFO -   Generated 33 RDF triples\n",
            "2025-12-15 16:20:14,350 - INFO - Processing post: falcon_6\n",
            "2025-12-15 16:20:14,353 - INFO - Extracting claims from post: falcon_6\n",
            "2025-12-15 16:20:14,818 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:15,649 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:20:15,649 - INFO - Detecting persuasion in claim: falcon_6_1\n",
            "2025-12-15 16:20:15,657 - INFO - Detecting persuasion in claim: falcon_6_2\n",
            "2025-12-15 16:20:15,662 - INFO - Detecting persuasion in claim: falcon_6_3\n",
            "2025-12-15 16:20:15,667 - INFO -   Detected 3 persuasion techniques\n",
            "2025-12-15 16:20:15,668 - INFO - Extracting entities from claim: falcon_6_1\n",
            "2025-12-15 16:20:15,739 - INFO - Extracting entities from claim: falcon_6_2\n",
            "2025-12-15 16:20:15,763 - INFO - Extracting entities from claim: falcon_6_3\n",
            "2025-12-15 16:20:15,781 - INFO -   Linked 0 entities\n",
            "2025-12-15 16:20:15,783 - INFO - Verifying claim: falcon_6_1\n",
            "2025-12-15 16:20:15,784 - INFO - Verifying claim: falcon_6_2\n",
            "2025-12-15 16:20:15,786 - INFO - Verifying claim: falcon_6_3\n",
            "2025-12-15 16:20:15,787 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:15,789 - INFO - Generating RDF triples for post: falcon_6\n",
            "2025-12-15 16:20:15,790 - INFO -   Generated 25 RDF triples\n",
            "2025-12-15 16:20:15,793 - INFO - Processing post: falcon_7\n",
            "2025-12-15 16:20:15,795 - INFO - Extracting claims from post: falcon_7\n",
            "2025-12-15 16:20:16,178 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:16,453 - INFO -   Extracted 1 claims\n",
            "2025-12-15 16:20:16,460 - INFO - Detecting persuasion in claim: falcon_7_1\n",
            "2025-12-15 16:20:16,863 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:18,204 - INFO -   Detected 3 persuasion techniques\n",
            "2025-12-15 16:20:18,206 - INFO - Extracting entities from claim: falcon_7_1\n",
            "2025-12-15 16:20:18,224 - INFO -   Linked 0 entities\n",
            "2025-12-15 16:20:18,227 - INFO - Verifying claim: falcon_7_1\n",
            "2025-12-15 16:20:18,227 - INFO -   Verified 1 claims\n",
            "2025-12-15 16:20:18,229 - INFO - Generating RDF triples for post: falcon_7\n",
            "2025-12-15 16:20:18,231 - INFO -   Generated 17 RDF triples\n",
            "2025-12-15 16:20:18,234 - INFO - Processing post: falcon_8\n",
            "2025-12-15 16:20:18,235 - INFO - Extracting claims from post: falcon_8\n",
            "2025-12-15 16:20:18,713 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:19,237 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:20:19,238 - INFO - Detecting persuasion in claim: falcon_8_1\n",
            "2025-12-15 16:20:19,241 - INFO - Detecting persuasion in claim: falcon_8_2\n",
            "2025-12-15 16:20:19,247 - INFO - Detecting persuasion in claim: falcon_8_3\n",
            "2025-12-15 16:20:19,247 - INFO -   Detected 3 persuasion techniques\n",
            "2025-12-15 16:20:19,250 - INFO - Extracting entities from claim: falcon_8_1\n",
            "2025-12-15 16:20:19,269 - INFO - Extracting entities from claim: falcon_8_2\n",
            "2025-12-15 16:20:19,284 - INFO - Extracting entities from claim: falcon_8_3\n",
            "2025-12-15 16:20:19,297 - INFO -   Linked 0 entities\n",
            "2025-12-15 16:20:19,298 - INFO - Verifying claim: falcon_8_1\n",
            "2025-12-15 16:20:19,299 - INFO - Verifying claim: falcon_8_2\n",
            "2025-12-15 16:20:19,300 - INFO - Verifying claim: falcon_8_3\n",
            "2025-12-15 16:20:19,301 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:19,301 - INFO - Generating RDF triples for post: falcon_8\n",
            "2025-12-15 16:20:19,305 - INFO -   Generated 25 RDF triples\n",
            "2025-12-15 16:20:19,305 - INFO - Processing post: falcon_9\n",
            "2025-12-15 16:20:19,306 - INFO - Extracting claims from post: falcon_9\n",
            "2025-12-15 16:20:19,830 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:20,158 - INFO -   Extracted 1 claims\n",
            "2025-12-15 16:20:20,163 - INFO - Detecting persuasion in claim: falcon_9_1\n",
            "2025-12-15 16:20:20,169 - INFO -   Detected 1 persuasion techniques\n",
            "2025-12-15 16:20:20,174 - INFO - Extracting entities from claim: falcon_9_1\n",
            "2025-12-15 16:20:20,419 - INFO -   Linked 1 entities\n",
            "2025-12-15 16:20:20,424 - INFO - Verifying claim: falcon_9_1\n",
            "2025-12-15 16:20:20,430 - INFO -   Verified 1 claims\n",
            "2025-12-15 16:20:20,435 - INFO - Generating RDF triples for post: falcon_9\n",
            "2025-12-15 16:20:20,444 - INFO -   Generated 18 RDF triples\n",
            "2025-12-15 16:20:20,447 - INFO - Processing batch 3\n",
            "2025-12-15 16:20:20,449 - INFO - Processing post: falcon_10\n",
            "2025-12-15 16:20:20,453 - INFO - Extracting claims from post: falcon_10\n",
            "2025-12-15 16:20:20,963 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:21,373 - INFO -   Extracted 2 claims\n",
            "2025-12-15 16:20:21,377 - INFO - Detecting persuasion in claim: falcon_10_1\n",
            "2025-12-15 16:20:21,384 - INFO - Detecting persuasion in claim: falcon_10_2\n",
            "2025-12-15 16:20:21,388 - INFO -   Detected 2 persuasion techniques\n",
            "2025-12-15 16:20:21,389 - INFO - Extracting entities from claim: falcon_10_1\n",
            "2025-12-15 16:20:27,050 - INFO - Extracting entities from claim: falcon_10_2\n",
            "2025-12-15 16:20:27,199 - INFO -   Linked 2 entities\n",
            "2025-12-15 16:20:27,201 - INFO - Verifying claim: falcon_10_1\n",
            "2025-12-15 16:20:27,205 - INFO - Verifying claim: falcon_10_2\n",
            "2025-12-15 16:20:27,209 - INFO -   Verified 2 claims\n",
            "2025-12-15 16:20:27,211 - INFO - Generating RDF triples for post: falcon_10\n",
            "2025-12-15 16:20:27,225 - INFO -   Generated 28 RDF triples\n",
            "2025-12-15 16:20:27,230 - INFO - Processing post: falcon_11\n",
            "2025-12-15 16:20:27,233 - INFO - Extracting claims from post: falcon_11\n",
            "2025-12-15 16:20:27,718 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:28,368 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:20:28,370 - INFO - Detecting persuasion in claim: falcon_11_1\n",
            "2025-12-15 16:20:28,376 - INFO - Detecting persuasion in claim: falcon_11_2\n",
            "2025-12-15 16:20:28,379 - INFO - Detecting persuasion in claim: falcon_11_3\n",
            "2025-12-15 16:20:28,381 - INFO -   Detected 3 persuasion techniques\n",
            "2025-12-15 16:20:28,384 - INFO - Extracting entities from claim: falcon_11_1\n",
            "2025-12-15 16:20:28,447 - INFO - Extracting entities from claim: falcon_11_2\n",
            "2025-12-15 16:20:28,473 - INFO - Extracting entities from claim: falcon_11_3\n",
            "2025-12-15 16:20:28,489 - INFO -   Linked 0 entities\n",
            "2025-12-15 16:20:28,490 - INFO - Verifying claim: falcon_11_1\n",
            "2025-12-15 16:20:28,490 - INFO - Verifying claim: falcon_11_2\n",
            "2025-12-15 16:20:28,493 - INFO - Verifying claim: falcon_11_3\n",
            "2025-12-15 16:20:28,495 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:28,497 - INFO - Generating RDF triples for post: falcon_11\n",
            "2025-12-15 16:20:28,499 - INFO -   Generated 25 RDF triples\n",
            "2025-12-15 16:20:28,499 - INFO - Processing post: falcon_12\n",
            "2025-12-15 16:20:28,499 - INFO - Extracting claims from post: falcon_12\n",
            "2025-12-15 16:20:29,159 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:29,464 - INFO -   Extracted 1 claims\n",
            "2025-12-15 16:20:29,469 - INFO - Detecting persuasion in claim: falcon_12_1\n",
            "2025-12-15 16:20:29,473 - INFO -   Detected 2 persuasion techniques\n",
            "2025-12-15 16:20:29,476 - INFO - Extracting entities from claim: falcon_12_1\n",
            "2025-12-15 16:20:46,082 - INFO -   Linked 2 entities\n",
            "2025-12-15 16:20:46,086 - INFO - Verifying claim: falcon_12_1\n",
            "2025-12-15 16:20:46,088 - INFO -   Verified 1 claims\n",
            "2025-12-15 16:20:46,092 - INFO - Generating RDF triples for post: falcon_12\n",
            "2025-12-15 16:20:46,099 - INFO -   Generated 24 RDF triples\n",
            "2025-12-15 16:20:46,099 - INFO - Processing post: falcon_13\n",
            "2025-12-15 16:20:46,104 - INFO - Extracting claims from post: falcon_13\n",
            "2025-12-15 16:20:46,561 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:46,921 - INFO -   Extracted 1 claims\n",
            "2025-12-15 16:20:46,925 - INFO - Detecting persuasion in claim: falcon_13_1\n",
            "2025-12-15 16:20:47,312 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:48,748 - INFO -   Detected 4 persuasion techniques\n",
            "2025-12-15 16:20:48,755 - INFO - Extracting entities from claim: falcon_13_1\n",
            "2025-12-15 16:20:48,920 - INFO -   Linked 1 entities\n",
            "2025-12-15 16:20:48,924 - INFO - Verifying claim: falcon_13_1\n",
            "2025-12-15 16:20:48,925 - INFO -   Verified 1 claims\n",
            "2025-12-15 16:20:48,927 - INFO - Generating RDF triples for post: falcon_13\n",
            "2025-12-15 16:20:48,930 - INFO -   Generated 23 RDF triples\n",
            "2025-12-15 16:20:48,933 - INFO - Processing post: falcon_14\n",
            "2025-12-15 16:20:48,934 - INFO - Extracting claims from post: falcon_14\n",
            "2025-12-15 16:20:49,310 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-12-15 16:20:50,044 - INFO -   Extracted 3 claims\n",
            "2025-12-15 16:20:50,048 - INFO - Detecting persuasion in claim: falcon_14_1\n",
            "2025-12-15 16:20:50,051 - INFO - Detecting persuasion in claim: falcon_14_2\n",
            "2025-12-15 16:20:50,059 - INFO - Detecting persuasion in claim: falcon_14_3\n",
            "2025-12-15 16:20:50,063 - INFO -   Detected 3 persuasion techniques\n",
            "2025-12-15 16:20:50,067 - INFO - Extracting entities from claim: falcon_14_1\n",
            "2025-12-15 16:20:50,115 - INFO - Extracting entities from claim: falcon_14_2\n",
            "2025-12-15 16:20:50,153 - INFO - Extracting entities from claim: falcon_14_3\n",
            "2025-12-15 16:20:50,184 - INFO -   Linked 0 entities\n",
            "2025-12-15 16:20:50,188 - INFO - Verifying claim: falcon_14_1\n",
            "2025-12-15 16:20:50,188 - INFO - Verifying claim: falcon_14_2\n",
            "2025-12-15 16:20:50,193 - INFO - Verifying claim: falcon_14_3\n",
            "2025-12-15 16:20:50,193 - INFO -   Verified 3 claims\n",
            "2025-12-15 16:20:50,197 - INFO - Generating RDF triples for post: falcon_14\n",
            "2025-12-15 16:20:50,201 - INFO -   Generated 25 RDF triples\n",
            "2025-12-15 16:20:50,236 - INFO - Serialized RDF to: data\\output\\annotated_posts.ttl\n",
            "2025-12-15 16:20:50,266 - INFO - Serialized RDF to: data\\output\\annotated_posts.json-ld\n",
            "2025-12-15 16:20:50,268 - INFO - Saved statistics to: data\\output\\pipeline_stats.json\n",
            "2025-12-15 16:20:50,270 - INFO - ✓ Pipeline complete!\n",
            "2025-12-15 16:20:50,271 - INFO -   Turtle output: data\\output\\annotated_posts.ttl\n",
            "2025-12-15 16:20:50,271 - INFO -   JSON-LD output: data\\output\\annotated_posts.json-ld\n",
            "2025-12-15 16:20:50,273 - INFO -   Total triples: 390\n",
            "2025-12-15 16:20:50,273 - INFO -   Statistics: {'total_posts': 15, 'total_claims': 34, 'total_techniques': 57, 'total_entities': 18, 'technique_counts': {'FalseDilemma': 13, 'LoadedLanguage': 23, 'FearAppeal': 3, 'Exaggeration': 2, 'HastyGeneralization': 7, 'Scapegoating': 6, 'AppealToRidicule': 1, 'AdHominem': 2}}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "PIPELINE COMPLETE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Import and run pipeline\n",
        "from pipeline_implementation import main_pipeline, Config\n",
        "\n",
        "print(f\"Input file: {Config.INPUT_FILE}\")\n",
        "print(f\"Max posts to process: {Config.MAX_POSTS}\")\n",
        "print(f\"Confidence threshold: {Config.CONFIDENCE_THRESHOLD}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RUNNING PIPELINE...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Run pipeline\n",
        "result = main_pipeline(use_falcon=True, max_posts=Config.MAX_POSTS)\n",
        "\n",
        "if result is None:\n",
        "    raise RuntimeError(\"Pipeline failed - check error messages above\")\n",
        "\n",
        "graph, stats = result\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PIPELINE COMPLETE\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Results Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Load Pipeline Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline Statistics:\n",
            "==================================================\n",
            "Total posts processed:    15\n",
            "Total claims extracted:   34\n",
            "Total techniques found:   57\n",
            "Total entities linked:    18\n",
            "\n",
            "Avg claims per post:      2.27\n",
            "Avg techniques per post:  3.80\n"
          ]
        }
      ],
      "source": [
        "# Load statistics from pipeline output\n",
        "stats_path = OUTPUT_DIR / \"pipeline_stats.json\"\n",
        "with open(stats_path) as f:\n",
        "    pipeline_stats = json.load(f)\n",
        "\n",
        "print(\"Pipeline Statistics:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total posts processed:    {pipeline_stats['total_posts']}\")\n",
        "print(f\"Total claims extracted:   {pipeline_stats['total_claims']}\")\n",
        "print(f\"Total techniques found:   {pipeline_stats['total_techniques']}\")\n",
        "print(f\"Total entities linked:    {pipeline_stats['total_entities']}\")\n",
        "print(f\"\\nAvg claims per post:      {pipeline_stats['total_claims']/pipeline_stats['total_posts']:.2f}\")\n",
        "print(f\"Avg techniques per post:  {pipeline_stats['total_techniques']/pipeline_stats['total_posts']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Technique Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Persuasion Techniques:\n",
            "==================================================\n",
            "LoadedLanguage              23 ( 40.4%) ████████████████████\n",
            "FalseDilemma                13 ( 22.8%) ███████████\n",
            "HastyGeneralization          7 ( 12.3%) ██████\n",
            "Scapegoating                 6 ( 10.5%) █████\n",
            "FearAppeal                   3 (  5.3%) ██\n",
            "Exaggeration                 2 (  3.5%) █\n",
            "AdHominem                    2 (  3.5%) █\n",
            "AppealToRidicule             1 (  1.8%) \n"
          ]
        }
      ],
      "source": [
        "# Technique breakdown\n",
        "print(\"Detected Persuasion Techniques:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "technique_counts = pipeline_stats.get('technique_counts', {})\n",
        "total_techniques = sum(technique_counts.values())\n",
        "\n",
        "# Sort by count descending\n",
        "sorted_techniques = sorted(technique_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for technique, count in sorted_techniques:\n",
        "    pct = count / total_techniques * 100 if total_techniques > 0 else 0\n",
        "    bar = \"█\" * int(pct / 2)\n",
        "    print(f\"{technique:25} {count:4} ({pct:5.1f}%) {bar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Compare with Ground Truth (FALCON Labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground Truth vs Detected Techniques:\n",
            "============================================================\n",
            "Technique                 Ground Truth     Detected\n",
            "------------------------------------------------------------\n",
            "AdHominem                            1            2\n",
            "AppealToRidicule                     0            1\n",
            "Exaggeration                         0            2\n",
            "FalseDilemma                         3           13\n",
            "FearAppeal                           0            3\n",
            "HastyGeneralization                  2            7\n",
            "LoadedLanguage                       5           23\n",
            "Scapegoating                         0            6\n",
            "------------------------------------------------------------\n",
            "TOTAL                               11           57\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load processed FALCON data with ground truth labels\n",
        "falcon_path = INPUT_DIR / \"falcon_processed.json\"\n",
        "with open(falcon_path) as f:\n",
        "    falcon_data = json.load(f)\n",
        "\n",
        "# Get ground truth for processed posts\n",
        "processed_posts = falcon_data[:pipeline_stats['total_posts']]\n",
        "\n",
        "# Count ground truth techniques\n",
        "gt_techniques = []\n",
        "for post in processed_posts:\n",
        "    gt_techniques.extend(post.get('techniques', []))\n",
        "\n",
        "gt_counts = Counter(gt_techniques)\n",
        "\n",
        "print(\"Ground Truth vs Detected Techniques:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Technique':<25} {'Ground Truth':>12} {'Detected':>12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "all_techniques = set(gt_counts.keys()) | set(technique_counts.keys())\n",
        "for tech in sorted(all_techniques):\n",
        "    gt = gt_counts.get(tech, 0)\n",
        "    detected = technique_counts.get(tech, 0)\n",
        "    print(f\"{tech:<25} {gt:>12} {detected:>12}\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'TOTAL':<25} {sum(gt_counts.values()):>12} {sum(technique_counts.values()):>12}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 RDF Knowledge Graph Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Knowledge Graph Statistics:\n",
            "==================================================\n",
            "Total RDF triples: 390\n",
            "\n",
            "Node types:\n",
            "  Claim: <built-in method count of ResultRow object at 0x0000027AA2C3D8B0>\n",
            "  Post: <built-in method count of ResultRow object at 0x0000027AA1341B30>\n",
            "  Entity: <built-in method count of ResultRow object at 0x0000027A9F5EA710>\n",
            "  LLMAgent: <built-in method count of ResultRow object at 0x0000027AA2C3D8B0>\n"
          ]
        }
      ],
      "source": [
        "from rdflib import Graph, Namespace\n",
        "\n",
        "# Load generated RDF\n",
        "ttl_path = OUTPUT_DIR / \"annotated_posts.ttl\"\n",
        "kg = Graph()\n",
        "kg.parse(ttl_path, format=\"turtle\")\n",
        "\n",
        "print(f\"Knowledge Graph Statistics:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total RDF triples: {len(kg)}\")\n",
        "\n",
        "# Count by type\n",
        "PERSUASION = Namespace(\"http://example.org/persuasion#\")\n",
        "\n",
        "type_query = \"\"\"\n",
        "PREFIX persuasion: <http://example.org/persuasion#>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\n",
        "SELECT ?type (COUNT(?s) as ?count)\n",
        "WHERE {\n",
        "    ?s rdf:type ?type .\n",
        "    FILTER(STRSTARTS(STR(?type), \"http://example.org/persuasion#\"))\n",
        "}\n",
        "GROUP BY ?type\n",
        "ORDER BY DESC(?count)\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nNode types:\")\n",
        "for row in kg.query(type_query):\n",
        "    type_name = str(row.type).split(\"#\")[-1]\n",
        "    print(f\"  {type_name}: {row.count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Comparison with Baseline (MUSE Framework)\n",
        "\n",
        "We compare our approach with the **MUSE** framework (Zhou et al., 2024), which is the baseline for persuasion-aware misinformation correction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Comparison: MUSE vs Our Approach\n",
            "======================================================================\n",
            "                     Feature        MUSE (Baseline)          Our Approach\n",
            "               Output Format Plain text corrections   RDF Knowledge Graph\n",
            "   Queryable Knowledge Graph                     No                   Yes\n",
            "   Entity Linking (Wikidata)                     No                   Yes\n",
            "Provenance Tracking (PROV-O)                     No                   Yes\n",
            "  Persuasion Technique Types                4 types 8+ types (extensible)\n",
            "            Claim Extraction              Yes (LLM)             Yes (LLM)\n",
            "     Structured Explanations             Text-based        Semantic (RDF)\n",
            "             SPARQL Querying                     No                   Yes\n",
            "         Multi-format Export                     No    Yes (TTL, JSON-LD)\n"
          ]
        }
      ],
      "source": [
        "# Baseline comparison table\n",
        "comparison = {\n",
        "    \"Feature\": [\n",
        "        \"Output Format\",\n",
        "        \"Queryable Knowledge Graph\",\n",
        "        \"Entity Linking (Wikidata)\",\n",
        "        \"Provenance Tracking (PROV-O)\",\n",
        "        \"Persuasion Technique Types\",\n",
        "        \"Claim Extraction\",\n",
        "        \"Structured Explanations\",\n",
        "        \"SPARQL Querying\",\n",
        "        \"Multi-format Export\"\n",
        "    ],\n",
        "    \"MUSE (Baseline)\": [\n",
        "        \"Plain text corrections\",\n",
        "        \"No\",\n",
        "        \"No\",\n",
        "        \"No\",\n",
        "        \"4 types\",\n",
        "        \"Yes (LLM)\",\n",
        "        \"Text-based\",\n",
        "        \"No\",\n",
        "        \"No\"\n",
        "    ],\n",
        "    \"Our Approach\": [\n",
        "        \"RDF Knowledge Graph\",\n",
        "        \"Yes\",\n",
        "        \"Yes\",\n",
        "        \"Yes\",\n",
        "        \"8+ types (extensible)\",\n",
        "        \"Yes (LLM)\",\n",
        "        \"Semantic (RDF)\",\n",
        "        \"Yes\",\n",
        "        \"Yes (TTL, JSON-LD)\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison)\n",
        "print(\"Feature Comparison: MUSE vs Our Approach\")\n",
        "print(\"=\" * 70)\n",
        "print(df_comparison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Key Advantages of Our Approach\n",
        "\n",
        "1. **Structured Knowledge Representation**: RDF enables machine reasoning\n",
        "2. **Entity Disambiguation**: Wikidata linking provides unambiguous entity references  \n",
        "3. **Queryability**: SPARQL allows complex analytical queries\n",
        "4. **Provenance**: PROV-O tracks how annotations were generated\n",
        "5. **Interoperability**: Standard formats (TTL, JSON-LD) enable data sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. SPARQL Query Examples\n",
        "\n",
        "Demonstrating the queryability of our knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query 1: Posts with >2 persuasion techniques\n",
            "==================================================\n",
            "Post falcon_2: 5 techniques\n",
            "Post falcon_0: 4 techniques\n",
            "Post falcon_1: 4 techniques\n",
            "Post falcon_13: 4 techniques\n",
            "Post falcon_4: 3 techniques\n",
            "Post falcon_7: 3 techniques\n"
          ]
        }
      ],
      "source": [
        "# Query 1: Posts with multiple persuasion techniques\n",
        "query1 = \"\"\"\n",
        "PREFIX persuasion: <http://example.org/persuasion#>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\n",
        "SELECT ?postId (COUNT(DISTINCT ?technique) as ?techniqueCount)\n",
        "WHERE {\n",
        "    ?post rdf:type persuasion:Post ;\n",
        "          persuasion:postId ?postId ;\n",
        "          persuasion:containsClaim ?claim .\n",
        "    ?claim persuasion:usesTechnique ?technique .\n",
        "}\n",
        "GROUP BY ?postId\n",
        "HAVING (COUNT(DISTINCT ?technique) > 2)\n",
        "ORDER BY DESC(?techniqueCount)\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "print(\"Query 1: Posts with >2 persuasion techniques\")\n",
        "print(\"=\" * 50)\n",
        "results = list(kg.query(query1))\n",
        "if results:\n",
        "    for row in results:\n",
        "        print(f\"Post {row.postId}: {row.techniqueCount} techniques\")\n",
        "else:\n",
        "    print(\"No posts with >2 techniques found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query 2: Entities linked to Wikidata\n",
            "==================================================\n",
            "1: Q27721\n",
            "1st: Q956209\n",
            "George Floyd: Q5539328\n",
            "Milwaukee Bucks: Q169637\n",
            "Supermax: Q7643958\n",
            "Trump: Q2643970\n"
          ]
        }
      ],
      "source": [
        "# Query 2: Entities linked to Wikidata\n",
        "query2 = \"\"\"\n",
        "PREFIX persuasion: <http://example.org/persuasion#>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\n",
        "SELECT ?entityName ?wikidataId\n",
        "WHERE {\n",
        "    ?entity rdf:type persuasion:Entity ;\n",
        "            persuasion:entityName ?entityName ;\n",
        "            persuasion:linkedToWikidata ?wikidataId .\n",
        "}\n",
        "ORDER BY ?entityName\n",
        "LIMIT 15\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nQuery 2: Entities linked to Wikidata\")\n",
        "print(\"=\" * 50)\n",
        "for row in kg.query(query2):\n",
        "    wikidata_id = str(row.wikidataId).split(\"/\")[-1]\n",
        "    print(f\"{row.entityName}: {wikidata_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query 3: Technique-Entity Combinations\n",
            "==================================================\n",
            "No technique-entity combinations found\n"
          ]
        }
      ],
      "source": [
        "# Query 3: Most common technique-entity combinations\n",
        "query3 = \"\"\"\n",
        "PREFIX persuasion: <http://example.org/persuasion#>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\n",
        "SELECT ?techniqueName ?entityName (COUNT(*) as ?count)\n",
        "WHERE {\n",
        "    ?claim persuasion:usesTechnique ?technique ;\n",
        "           persuasion:mentionsEntity ?entity .\n",
        "    ?entity persuasion:entityName ?entityName .\n",
        "    BIND(STRAFTER(STR(?technique), \"#\") AS ?techniqueName)\n",
        "}\n",
        "GROUP BY ?techniqueName ?entityName\n",
        "ORDER BY DESC(?count)\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nQuery 3: Technique-Entity Combinations\")\n",
        "print(\"=\" * 50)\n",
        "results = list(kg.query(query3))\n",
        "if results:\n",
        "    for row in results:\n",
        "        print(f\"{row.techniqueName} + {row.entityName}: {row.count}\")\n",
        "else:\n",
        "    print(\"No technique-entity combinations found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Insights and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "EXPERIMENTAL RESULTS SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Dataset: FALCON (COVID-19 fallacy detection)\n",
            "Posts Processed: 15\n",
            "Claims Extracted: 34\n",
            "Persuasion Techniques Detected: 57\n",
            "Entities Linked to Wikidata: 18\n",
            "RDF Triples Generated: 390\n",
            "\n",
            "KEY FINDINGS:\n",
            "─────────────────────────────────────────────────────────────────────\n",
            "1. LoadedLanguage is the most frequently detected technique\n",
            "   - Consistent with FALCON ground truth distribution\n",
            "   - Reflects emotional manipulation in COVID-19 discourse\n",
            "\n",
            "2. LLM-based detection finds techniques beyond ground truth labels\n",
            "   - Scapegoating and Exaggeration detected but not in original labels\n",
            "   - Shows potential for richer annotation than human labeling\n",
            "\n",
            "3. Entity linking provides context for claim analysis\n",
            "   - 18 entities linked to Wikidata\n",
            "   - Enables cross-referencing with external knowledge\n",
            "\n",
            "4. RDF representation enables complex queries\n",
            "   - SPARQL queries can find patterns across posts\n",
            "   - Supports automated reasoning and analysis\n",
            "\n",
            "ADVANTAGES OVER MUSE BASELINE:\n",
            "─────────────────────────────────────────────────────────────────────\n",
            "✓ Structured output (RDF vs plain text)\n",
            "✓ Machine-queryable knowledge graph\n",
            "✓ Entity disambiguation via Wikidata\n",
            "✓ Provenance tracking (PROV-O)\n",
            "✓ Interoperable formats (Turtle, JSON-LD)\n",
            "\n",
            "LIMITATIONS:\n",
            "─────────────────────────────────────────────────────────────────────\n",
            "- Fact-checking module is placeholder (requires external APIs)\n",
            "- LLM detection may hallucinate techniques not present\n",
            "- Processing speed limited by API rate limits\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Summary insights\n",
        "print(\"=\"*70)\n",
        "print(\"EXPERIMENTAL RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "Dataset: FALCON (COVID-19 fallacy detection)\n",
        "Posts Processed: {pipeline_stats['total_posts']}\n",
        "Claims Extracted: {pipeline_stats['total_claims']}\n",
        "Persuasion Techniques Detected: {pipeline_stats['total_techniques']}\n",
        "Entities Linked to Wikidata: {pipeline_stats['total_entities']}\n",
        "RDF Triples Generated: {len(kg)}\n",
        "\n",
        "KEY FINDINGS:\n",
        "─────────────────────────────────────────────────────────────────────\n",
        "1. LoadedLanguage is the most frequently detected technique\n",
        "   - Consistent with FALCON ground truth distribution\n",
        "   - Reflects emotional manipulation in COVID-19 discourse\n",
        "\n",
        "2. LLM-based detection finds techniques beyond ground truth labels\n",
        "   - Scapegoating and Exaggeration detected but not in original labels\n",
        "   - Shows potential for richer annotation than human labeling\n",
        "\n",
        "3. Entity linking provides context for claim analysis\n",
        "   - {pipeline_stats['total_entities']} entities linked to Wikidata\n",
        "   - Enables cross-referencing with external knowledge\n",
        "\n",
        "4. RDF representation enables complex queries\n",
        "   - SPARQL queries can find patterns across posts\n",
        "   - Supports automated reasoning and analysis\n",
        "\n",
        "ADVANTAGES OVER MUSE BASELINE:\n",
        "─────────────────────────────────────────────────────────────────────\n",
        "✓ Structured output (RDF vs plain text)\n",
        "✓ Machine-queryable knowledge graph\n",
        "✓ Entity disambiguation via Wikidata\n",
        "✓ Provenance tracking (PROV-O)\n",
        "✓ Interoperable formats (Turtle, JSON-LD)\n",
        "\n",
        "LIMITATIONS:\n",
        "─────────────────────────────────────────────────────────────────────\n",
        "- Fact-checking module is placeholder (requires external APIs)\n",
        "- LLM detection may hallucinate techniques not present\n",
        "- Processing speed limited by API rate limits\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Output Files\n",
        "\n",
        "Generated artifacts:\n",
        "- `data/output/annotated_posts.ttl` - RDF in Turtle format\n",
        "- `data/output/annotated_posts.json-ld` - RDF in JSON-LD format\n",
        "- `data/output/pipeline_stats.json` - Execution statistics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
